## Unreal Log parser project overview

A backend service for parsing and analizing the log files that are generated by the Unreal Engine build process.<br>
With a Grafana dashboard to better visualize parsed issues their status and severity.

### Setup.

Create a virtual environment for the project and install dependencies.<br>

You can use the following command to create the virtual environment. <br> 
```bash
python -m venv .venv
```

Activate the `.venv` using:

```bash
source .venv/bin/activate
```

Install dependencies:
```bash
pip install -r requirements.txt
```
The project is based on `docker-compose` so make sure you have the appropriate software installed. <br>
During the developement version of `docker-compose` 2.29.6 was used.<br>

### Starting the project:

To start the project use the following command: 

```bash
docker-compose up --build
```
This will build all the images used by the app.<br>
*Note: after successfull image build, please give some time for the app to start properly before inserting logfiles. (around 1 minute should be sufficient)*  

Grafana will be available at [http://localhost:3000](http://localhost:3000)<br>
The API will be available at `http://localhost:8000`

### Inserting the Logfiles

You can inset logfiles using the code provided in `build.py` by running:

```python3
python3 build.py --insert-logfile=<logfile_path>
```
You can insert many logfiles by providing paths to the files separated by comma `,` <br>
```python3
python3 build.py --insert-logfile=<logfile_path1>,<logfile_path2>
```

Each of the files must be MAX 10 MB of size, otherwise it will be rejected by the backend.<br>


### What happens after upload?

Upon uploading the files they will be parsed. Found *Warnings*, *Errors* and *Tracebacks* will be inserted to *PostgreSQL* database.<br>
Whole unmodified lines from the file will be inserted to the *Elasticsearch* for future reference and access.<br>

The found issues are *deduplicated* so by the message and only single instance of a particular error/warning is present in the database at a time.<br>

Issues have generated id hash that is the same for entries in the Postgres, Elasticsearch and the results saved in the parsed file for ease of referencing the interesing lines.<br>

### Available API endpoints

You can test the API with standard tools like `curl`

```
POST	/logs	                            Process the logfile 
```
Issues (PostgreSQL)
```
GET	    /issues	                            Returns a list of issues with a open status (additionaly you can filter using ?status=open)
GET	    /issues/{log_entry_id}	            returns the issue based on id hash
POST	/issues	                            Inserts an issue by hand
PATCH	/issues/{log_entry_id}	            Updates the issue status (eg. open -> closed)
DELETE	/issues/{log_entry_id}	            Deletes a issue
```
Logs (Elasticsearch)
```
GET	    /logs/{log_entry_id}	            Returns specific log entry
GET	    /logs/{log_entry_id}/line_number	Returns a original line number from the logfile
GET	    /logs/{log_entry_id}/datetime	    Returns a timestamp associated with the log
```

### Visualization

There are two dashboards available that ware created in Grafana.<br>
- `Issues Dashboard` is Dashboard visualizing the parsed issues - Errors, Warnings and Tracebacks.
- `Logfile Browser` is for browsing the inserted logfiles.


### Testing available endpoints

You can test current endpoints using the `curl` command.<br>
Creating new issues (`log_entry_id` will be returned as a response):
```bash
curl -X POST "http://localhost:8000/issues" \
     -H "Content-Type: application/json" \
     -d '{"message":"Error #1 message","category":"LogEngine","status":"open","severity":"Error"}'
```
```bash
curl -X POST "http://localhost:8000/issues" \
     -H "Content-Type: application/json" \
     -d '{"message":"Error #2 message","category":"API","status":"open","severity":"Error"}'
```
We expect to recieve the `log_entry_id` hash, like "Oah9cUzNHNcrtwFfCt4A"<br>

List of all issues:<br>
```bash
curl "http://localhost:8000/issues"
```

List of filtered issues with status "open":<br>
```bash
curl "http://localhost:8000/issues?status=open"
```

Requesting a defails about a specific issue based on the `log_entry_id`:<br>
```bash
curl "http://localhost:8000/issues/<log_entry_id>"
```

Patching a existing issue based on `log_entry_id` hash eg. issue status from open to closed:<br>
```bash
curl -X PATCH "http://localhost:8000/issues/<log_entry_id>" \
     -H "Content-Type: application/json" \
     -d '{"new_status":"closed"}'
```

Removing issue:<br>
```bash
curl -X DELETE "http://localhost:8000/issues/<log_entry_id>"
```

Gathering full logline from Elasticsearch by the `log_entry_id` hash:<br>
```bash
curl "http://localhost:8000/logs/<log_entry_id>"
```

Getting date and time from log:<br>
```bash
curl "http://localhost:8000/logs/<log_entry_id>/datetime"
```

Getting the line number from log:<br>
```bash
curl "http://localhost:8000/logs/<log_entry_id>/line_number"
```
